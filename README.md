# ğŸ“Š Yelp Business Reviews Analysis | Endâ€‘toâ€‘End ELT Project

This project demonstrates a complete cloud-based data pipeline that ingests and analyzes large-scale Yelp review data using **Python**, **AWS S3**, and **Snowflake**. It covers ingestion, transformation, sentiment analysis, and insight extraction.

---

## ğŸš€ Project Highlights

- ğŸ“‚ **5GB+ raw dataset** in deeply nested JSON format
- ğŸª“ **Split into 20+ files** for scalable ingestion via Python
- â˜ï¸ **Uploaded to AWS S3** and loaded into Snowflake using external stages
- ğŸ§  **Sentiment analysis** using Python UDF with TextBlob inside Snowflake
- ğŸ“ˆ Performed advanced SQL analytics to uncover business insights

---

## ğŸ“ Repository Structure

yelp-review-analytics/
â”œâ”€â”€ notebooks/
â”‚ â””â”€â”€ split_and_upload.ipynb # Python code to split and upload dataset
â”œâ”€â”€ snowflake/
â”‚ â”œâ”€â”€ create_reviews_table.sql # [AWS credentials redacted]
â”‚ â”œâ”€â”€ create_business_table.sql # [AWS credentials redacted]
â”‚ â”œâ”€â”€ sentiment_udf.sql
â”œâ”€â”€ outputs/
â”‚ â””â”€â”€ analysis_queries.sql
â””â”€â”€ README.md

---

## âš ï¸ Data Accessibility

> âŒ **Dataset not included in repo due to size limits and privacy**
>
> Even the split JSON files (~25â€“30MB each) exceeded GitHubâ€™s 25MB upload limit via web interface.

You can download the full dataset or generate split files using the code provided.

ğŸ”— **Yelp Dataset**: [https://www.yelp.com/dataset](https://www.yelp.com/dataset)

---

## ğŸ” AWS Credentials Notice

The following files originally included sensitive AWS credentials and have been redacted:
- `create_reviews_table.sql`
- `create_business_table.sql`

Please configure your own **Snowflake storage integration** or use environment variables for secure access.

---

## ğŸ› ï¸ Tools & Tech Stack

| Tool          | Purpose                                 |
|---------------|------------------------------------------|
| Python        | Data splitting, S3 upload                |
| AWS S3        | Scalable object storage for raw data     |
| Snowflake     | Cloud data warehouse + SQL & Python UDFs |
| TextBlob      | Sentiment analysis (Python in Snowflake) |
| SQL           | Data transformation and insights         |

---

## ğŸ§  Key Steps

1. **Split JSON**  
   Preprocess the large Yelp review file into ~20 smaller chunks using Python.

2. **Upload to S3**  
   Store files in AWS S3 buckets (`/reviews/`, `/business/`) as a data lake.

3. **Snowflake External Stage**  
   Create external stages to load data using `VARIANT` and `LATERAL FLATTEN`.

4. **Sentiment Analysis**  
   Use a Python UDF with TextBlob inside Snowflake to classify each review.

5. **SQL Analytics**  
   Use CTEs, window functions, and aggregation to extract insights:
   - Top 3 recent reviews per business
   - Sentiment by city/category
   - Review trends

---

## ğŸ“ˆ Sample Insights

ğŸ” â€œ**Restaurants in Phoenix** have the highest average sentiment.â€  
ğŸ™ï¸ â€œ**Las Vegas nightlife** shows the most mixed reviews.â€  
ğŸ’¬ â€œ**Neutral sentiments** dominate reviews with 3-star ratings.â€

---

## ğŸ§ª Run It Yourself

1. ğŸ“¥ **Clone the repo**
2. ğŸ“‚ **Provide your own Yelp dataset**  
   Download the full dataset from [Yelp Open Dataset](https://www.yelp.com/dataset)  
   or use the included Python script to generate split files.
3. â˜ï¸ **Upload to your S3 bucket**
4. ğŸ§Š **Configure Snowflake storage integration** securely
5. ğŸ§  **Run the SQL scripts** to create tables, analyze sentiment, and extract insights

